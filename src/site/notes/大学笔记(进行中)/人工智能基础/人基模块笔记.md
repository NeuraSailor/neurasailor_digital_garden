---
{"dg-publish":true,"permalink":"////"}
---


# 人工智能学派分类

| 学派   | 核心思想                                                             | 主要成果                   | 应用                     |
| ---- | ---------------------------------------------------------------- | ---------------------- | ---------------------- |
| 符号主义 | 认为人类认知和思维的基本单元是符号，认知过程是以符号表示为基础的逻辑运算，计算机可以模拟人的智能行为。核心是构建符号表达知识。  | 机器定理程序、启发式算法、专家系统      | /                      |
| 联结主义 | 试图通过模拟大脑的神经网络来解释人类的认知功能，如记忆、学习、语言处理和模式识别。目标是实现模拟人脑的结构，产生了神经网络方法。 | 神经网络、深度学习、现代人工智能大语言模型  | 人脸识别，机器翻译，chatGPT，图像分类 |
| 行为主义 | 构建一个智能体，关注智能体在环境中的行为，智能体以最大化奖励为目标，与环境不断交互来学习和适应，会根据行为的结果进行调整。    | 强化学习、Q-learning 和策略梯度方法 | 游戏 AI、机器人控制、自动驾驶        |

# 机器学习分类
**1. 按照学习方式分类**:

|分类方式|定义|目标|应用场景|示例|
|---|---|---|---|---|
|监督学习|通过提供带标注的训练数据（输入-输出配对）来训练模型，模型学会将输入映射到输出。|找到一个函数 (f (x))，使其从输入 (x) 出发预测输出 (y)。|分类（垃圾邮件检测、图像识别、情感分析）；回归（房价预测、天气预测）。|邮件分类问题：输入邮件文本，输出"垃圾邮件" 或"非垃圾邮件"。|
|无监督学习|模型在没有任何标签（输出）的情况下，从输入数据中发现隐藏的模式或结构。|对数据进行聚类、降维或生成某种分布。|聚类（客户群体划分、图片分组）；降维（数据可视化、噪声过滤，如 PCA 主成分分析）；生成建模（生成数据的潜在分布，如 GAN 生成图像）。|网上消费行为分析：根据用户购买记录将用户分群，无需明确标签[高价值客户]、[低消费客户]。|
|强化学习|通过智能体与环境的交互来学习行为策略的方法，智能体通过试错机制获得奖励并优化自身策略。|最大化长期累积的奖励值。|游戏 AI（如 AlphaGo）；机器人控制；动态定价策略。|AlphaGo 对弈：智能体通过模拟围棋对局，优化其胜率策略。|

**2. 按照学习算法分类**:

| 分类方式  | 算法                                                    |
| ----- | ----------------------------------------------------- |
| 监督学习  | 线性回归、岭回归、Lasso 回归、支持向量机（SVM）、决策树、随机森林、逻辑回归、K 近邻算法、神经网络。 |
| 无监督学习 | K-Means、层次聚类、DBSCAN、PCA（主成分分析）、t-SNE。                 |
| 深度学习  | 卷积神经网络（CNN）、循环神经网络（RNN）、Transformer。[[大学笔记(进行中)/人工智能基础/人基模块笔记#深度学习\|人基模块笔记#深度学习]]   |
# 深度学习  

![|300](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250530084353321.png)
## 感知机 
![](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250530090612749.png)
![](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250531163729521.png)

### 激活函数
激活函数的作用是通过非线性变换，使神经网络具备非线性特性，以解决一些非线性任务

![PixPin_2025-05-30_09-16-18.png|300](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250530091639183.png)


单层感知机无法解决“异或问题  
## Mlp（多层感知机）  
只有一个隐含层的叫浅层学习网络，隐含层大于一层的叫深度学习网络  
处理一维向量数据
### 损失函数  
![|400](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250530091846449.png)
## BP 算法  
![](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250530094148132.png)  
1. **正向传播**：计算网络输出和损失函数值；
2. **反向传播**：根据链式法则计算损失函数对每个参数的梯度；
3. **梯度下降**：利用梯度更新参数，减少损失函数值；
### 梯度下降  


![](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250530094716269.png)
- **MLP 是一种网络结构**，拥有多层（输入层+隐藏层+输出层）和带非线性激活函数的节点，能够表示复杂的非线性函数。
    
- **反向传播算法（BP）是训练这种多层网络的关键算法**，它用来高效计算网络中每个参数（权重和偏置）对最终误差的梯度。
-  **MLP 是模型架构。**
- **BP 是训练 MLP 的算法**

# Cnn 卷积神经网络  
  
卷积神经网络是包含卷积运算的一种特殊前馈神经网络。卷积神经网络一般由卷积层 (convolution) 、汇聚/池化层  
(pooling) 和全连接层构成  
前面几层每一层进行卷积运算或汇聚/池化运算， 卷积实现的是**特征检测**， 汇聚/池化实现的是**特征选择**; 最后儿层是全连  
接的前馈神经网络，进行**分类或回归预测**。卷积神经网络是从生物视觉系统得到启发而发明的机器学习模型。  
## 卷积  
**特征检测**  
![](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250531165443888.png)
### 感受野  
首先进行局部处理，经过多个层次的局部处理提取出特征  
值，再逐层传递，这个局部的大小范围就是“感受野  
### 卷积运算  
> 卷积运算就是通过设计一系列大小适中的卷积核（感受野），对数字图  
像的各个通道分量（二维矩阵）进行卷积，**提取特征值**的过程。常用的卷积核大小  
为 3×3、5×5、7×7  

> 求核矩阵与每一个子矩阵的内积，产生一个𝐾 × 𝐿输出矩阵𝒀 =  
𝑦𝑘𝑙 𝐾×𝐿, 称此运算为卷积 (convolution ) 或二维卷积
#### 补齐/填充操作  
 > 在输入矩阵的周边添加元素为 0 的行和列，  
使卷积核能更充分地作用于输入矩阵边缘的元素

“滑”的范围更广

### 感受野，卷积核，滤波器  
> 卷积核（滤波器）对输入的局部区域（感受野）进行卷积操作，提取特征。感受野是衡量神经元输入空间范围的概念，卷积核（滤波器）是实现该操作的具体参数矩阵  

> 卷积核就是要训练的参数  ，训练卷积核的目的是使其对特征的提取更准确，多个卷积核提取不同特征  

![](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250531171822817.png)

## 池化  
在图像处理中，汇聚实现的是特征选择。最基本的情况是二维汇聚，输入是一个矩阵， 矩阵的一个元素表示一个  
特征，代表特征的检测值。汇聚运算实际是将汇聚核在输入矩阵上进行滑动，从汇聚核覆盖的特征检测值中选择  
一个最大值或平均值，这样可以有效地进行特征抽取。输出是一个缩小的矩阵，也就是进行了下采样  ![20250602113932810.png](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250602113932810.png)  
![](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250602114912412.png)

## 归一化  
模型的训练需要高质量的数据，但是如果多个特征值的输入数据分布严重不均，数值范  
围差异巨大，则会产生训练不可收敛或者其他不可预料的问题。为解决这个问题，应保证让  
不同特征值的数据取值范围一致。最简单的处理方法就是归一化，即将特征值的取值范围压  
缩在 0~1 之间。  
$𝑦 = \frac{{𝑥 − min}}{max − min}$
## 程序题  
To_categorical：将标签转换为独热编码
Conv 2 D：卷积  
MaxPooling 2 D：池化  
Flatten：展平  
Dense：添加全连接层 mlp  
Model. Compile：编译模型  
Model. Fit：训练模型  
Model. Evaluate：评估模型  
Model. Evaluate：评估模型
Models. Load_model：加载模型  
Import matplotlib. Pyplot as plt......：可视化训练过程  

# Rnn, 循环神经网络 (Recurrent Neural Network)  
基于反馈神经网络  
![|600](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250602120725311.png)  
循环神经网络（Recurrent Neural Network，RNN）是一种特殊类型的反馈神经网络，专门用于处理序列数据。其核心思想是通过循环结构，使网络能够捕捉和利用序列中的顺序依赖性信息。  
![|600](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250602123441878.png)


![|600](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250602123252917.png)
# LSTM,长短期记忆网络（Long Short-Term Memory）  
RNN的问题：无法学习太长的序列，“很快忘记前面说过的话”  
长短期记忆网络（Long Short-Term Memory， LSTM ）：专门设计用于解决长期依赖的问题  
![](https://gitee.com/zjuwzy/obsidian_picture/raw/master/20250602124729319.png)
